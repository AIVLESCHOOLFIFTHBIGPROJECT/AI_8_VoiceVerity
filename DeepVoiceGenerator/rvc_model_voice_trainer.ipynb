{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3857,"status":"ok","timestamp":1721627753173,"user":{"displayName":"DongKyu Moon","userId":"13679376230758781592"},"user_tz":-540},"id":"Kx6__qjjq0eu","outputId":"9c050f5f-ce73-4f18-c054-1ad59c592ae3"},"outputs":[],"source":["## Common Libraries\n","import os\n","import threading\n","import time\n","import shutil\n","import hashlib\n","import time\n","import codecs\n","import shutil\n","import tarfile\n","import subprocess\n","from pathlib import Path\n","from datetime import datetime\n","## Model Libraries\n","import torch\n","print(f\"CUDA available: {torch.cuda.is_available()}\")\n","print(f\"CUDA device count: {torch.cuda.device_count()}\")\n","print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n","print(f\"CUDA device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Install Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":114259,"status":"ok","timestamp":1721627920296,"user":{"displayName":"DongKyu Moon","userId":"13679376230758781592"},"user_tz":-540},"id":"SZk2OhDxrp3b","outputId":"296405aa-6968-4b34-a9e7-3eb6789c5c7d"},"outputs":[],"source":["rot_47 = lambda encoded_text: \"\".join(\n","    [\n","        (\n","            chr(\n","                (ord(c) - (ord(\"a\") if c.islower() else ord(\"A\")) - 47) % 26\n","                + (ord(\"a\") if c.islower() else ord(\"A\"))\n","            )\n","            if c.isalpha()\n","            else c\n","        )\n","        for c in encoded_text\n","    ]\n",")\n","\n","E = Exception\n","B = print\n","\n","\n","def vidal_setup(ForceIn):\n","    L = \"Kikpm.ovm.bu\"\n","    K = \"/content/\"\n","    C = ForceIn\n","\n","    def F():\n","        print(\"Installing pip packages...\")\n","        subprocess.check_call([\"pip\", \"install\", \"-r\", \"requirements.txt\", \"--quiet\"])\n","\n","    A = K + rot_47(L)\n","    G = K + rot_47(L)\n","    D = \"/\"\n","    if not os.path.exists(A):\n","        M = os.path.dirname(A)\n","        os.makedirs(M, exist_ok=True)\n","        print(\"No cached install found..\")\n","        try:\n","            N = rot_47(\n","                codecs.decode(\n","                    \"pbbxa://pcooqvonikm.kw/QIPqaxivw/Ixxtqw/zmawtdm/uiqv/Kwtij/Xvxcz.biz.oh\",\n","                    \"rot_13\",\n","                )\n","            )\n","            subprocess.run([\"wget\", \"-O\", A, N])\n","            print(\"Download completed successfully!\")\n","        except E as H:\n","            print(str(H))\n","            if os.path.exists(A):\n","                os.remove(A)\n","    if Path(A).exists():\n","        with tarfile.open(G, \"r:gz\") as I:\n","            for J in I.getmembers():\n","                O = os.path.join(D, J.name)\n","                try:\n","                    I.extract(J, D)\n","                except E as H:\n","                    print(\"Failed to extract a file\")\n","                    C = True\n","            print(f\"Extraction of {G} to {D} completed.\")\n","        if os.path.exists(A):\n","            os.remove(A)\n","        if C:\n","            F()\n","            C = False\n","    else:\n","        F()\n","\n","\n","vidal_setup(False)\n","print(\"Finished installing requirements!\")"]},{"cell_type":"markdown","metadata":{"id":"qFVtVLU0q0ev"},"source":["## Parmeters Setting"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1091,"status":"ok","timestamp":1721627930910,"user":{"displayName":"DongKyu Moon","userId":"13679376230758781592"},"user_tz":-540},"id":"nr3g27Nkq0ew"},"outputs":[],"source":["model_name = \"Aivle_HanKY\"  # @param {type:\"string\"}\n","dataset_path = \"./train_han\"  # @param {type:\"string\"}\n","\n","sample_rate = \"48k\"  # @param [\"32k\", \"40k\", \"48k\"] {allow-input: false}\n","sr = int(sample_rate.rstrip(\"k\")) * 1000\n","cpu_cores = 2 # @param {type:\"slider\", min:1, max:2, step:1}\n","\n","rvc_version = \"v2\"  # @param [\"v2\", \"v1\"] {allow-input: false}\n","f0_method = \"rmvpe\"  # @param [\"pm\", \"dio\", \"crepe\", \"crepe-tiny\", \"harvest\", \"rmvpe\"] {allow-input: false}\n","pitch_guidance = True  # @param{type:\"boolean\"}\n","hop_length = 128  # @param {type:\"slider\", min:1, max:512, step:0}\n","\n","LOGS_FOLDER = \"./logs/\"\n","WEIGHTS_FOLDER = os.path.join(LOGS_FOLDER, model_name)\n","RVC_BK_PATH = \"./RVC_Backup\"\n","\n","total_epoch = 200  # @param {type:\"integer\"}\n","batch_size = 22  # @param {type:\"slider\", min:1, max:25, step:0}\n","gpu = 0\n","sr = int(sample_rate.rstrip(\"k\")) * 1000\n","pitch_guidance = True  # @param{type:\"boolean\"}\n","auto_backups = True  # @param{type:\"boolean\"}\n","pretrained = True  # @param{type:\"boolean\"}\n","sync_graph = False  # @param{type:\"boolean\"}\n","cache_data_in_gpu = True  # @param{type:\"boolean\"}\n","tensorboard = False  # @param{type:\"boolean\"}\n","# @markdown ### ➡️ Choose how many epochs your model will be stored\n","save_every_epoch = 20  # @param {type:\"slider\", min:1, max:100, step:0}\n","save_only_latest = False  # @param{type:\"boolean\"}\n","save_every_weights = True  # @param{type:\"boolean\"}\n","overtraining_detector = False  # @param{type:\"boolean\"}\n","overtraining_threshold = 50  # @param {type:\"slider\", min:1, max:100, step:0}\n","\n","# Optional\n","# In case you select custom pretrained, you will have to download the pretraineds and enter the path of the pretraineds.\n","custom_pretrained = False  # @param{type:\"boolean\"}\n","g_pretrained_path = \"./rvc/models/pretraineds/pretrained_v2/G48k.pth\"  # @param {type:\"string\"}\n","d_pretrained_path = \"./rvc/models/pretraineds/pretrained_v2/D48k.pth\"  # @param {type:\"string\"}\n","\n","if \"pretrained\" not in globals():\n","    pretrained = True\n","\n","if \"custom_pretrained\" not in globals():\n","    custom_pretrained = False\n","\n","if \"g_pretrained_path\" not in globals():\n","    g_pretrained_path = \"Custom Path\"\n","\n","if \"d_pretrained_path\" not in globals():\n","    d_pretrained_path = \"Custom Path\"\n","\n","model_epoch = 200  # @param {type:\"integer\"}\n","save_big_file = False  # @param {type:\"boolean\"}\n","model_path = os.path.join(\"./models\", model_name)\n"]},{"cell_type":"markdown","metadata":{"id":"ehyjlxysq0ew"},"source":["## Pre-Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":1472221,"status":"ok","timestamp":1721629415232,"user":{"displayName":"DongKyu Moon","userId":"13679376230758781592"},"user_tz":-540},"id":"PG4IZ6UTq0ew","outputId":"f26f65b1-6be5-460e-b657-7fc9a5fe397e"},"outputs":[],"source":["!python core.py prerequisites\n","!python core.py preprocess --model_name \"{model_name}\" --dataset_path \"{dataset_path}\" --sampling_rate \"{sr}\" --cpu_cores \"{cpu_cores}\"\n","!python core.py extract --model_name \"{model_name}\" --rvc_version \"{rvc_version}\" --f0_method \"{f0_method}\" --pitch_guidance \"{pitch_guidance}\" --hop_length \"{hop_length}\" --sampling_rate \"{sr}\" --cpu_cores \"{cpu_cores}\""]},{"cell_type":"markdown","metadata":{"id":"FcoZWUcaq0ew"},"source":["## RVC Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11132152,"status":"ok","timestamp":1721640630878,"user":{"displayName":"DongKyu Moon","userId":"13679376230758781592"},"user_tz":-540},"id":"DOsJpL9pq0ew","outputId":"67888f56-d476-4403-c6ea-af4124924ec7"},"outputs":[],"source":["def import_rvc_backup():\n","    print(\"Importing RVC backup...\")  # RVC 백업을 가져오는 작업 시작을 알림\n","    weights_exist = False  # 가중치 파일 존재 여부를 나타내는 플래그 초기화\n","    for root, dirs, files in os.walk(RVC_BK_PATH):  # RVC_BK_PATH 디렉토리를 순회하며 파일 목록을 탐색\n","        for filename in files:  # 각 파일에 대해 반복\n","            filepath = os.path.join(root, filename)  # 파일의 전체 경로 생성\n","            if os.path.isfile(filepath) and not filepath.startswith(\n","                os.path.join(RVC_BK_PATH, \"weights\")\n","            ):  # 파일이 존재하고 경로가 RVC_BK_PATH/weights로 시작하지 않는 경우\n","                backup_filepath = os.path.join(\n","                    LOGS_FOLDER, os.path.relpath(filepath, RVC_BK_PATH)\n","                )  # 백업 파일의 경로 생성\n","                backup_folderpath = os.path.dirname(backup_filepath)  # 백업 폴더 경로 생성\n","                if not os.path.exists(backup_folderpath):  # 백업 폴더가 존재하지 않는 경우\n","                    os.makedirs(backup_folderpath)  # 백업 폴더 생성\n","                    print(f\"Created backup folder: {backup_folderpath}\", flush=True)  # 폴더 생성 알림 출력\n","                shutil.copy2(filepath, backup_filepath)  # 파일을 메타데이터와 함께 복사\n","                print(f\"Imported file from RVC backup: {filename}\")  # 파일 복사 완료 알림 출력\n","            elif filepath.startswith(\n","                os.path.join(RVC_BK_PATH, \"weights\")\n","            ) and filename.endswith(\".pth\"):  # 파일 경로가 RVC_BK_PATH/weights로 시작하고 .pth 확장자인 경우\n","                weights_exist = True  # 가중치 파일 존재 여부 플래그 설정\n","                weights_filepath = os.path.join(\n","                    WEIGHTS_FOLDER,\n","                    os.path.relpath(\n","                        filepath, os.path.join(RVC_BK_PATH, \"weights\")\n","                    ),\n","                )  # 가중치 파일의 경로 생성\n","                weights_folderpath = os.path.dirname(weights_filepath)  # 가중치 폴더 경로 생성\n","                if not os.path.exists(weights_folderpath):  # 가중치 폴더가 존재하지 않는 경우\n","                    os.makedirs(weights_folderpath)  # 가중치 폴더 생성\n","                    print(f\"Created weights folder: {weights_folderpath}\", flush=True)  # 폴더 생성 알림 출력\n","                shutil.copy2(filepath, weights_filepath)  # 파일을 메타데이터와 함께 복사\n","                print(f\"Imported file from weights: {filename}\")  # 파일 복사 완료 알림 출력\n","    if weights_exist:  # 가중치 파일이 존재하는 경우\n","        print(\"Copied weights from RVC backup to local weights folder.\")  # 가중치 파일 복사 완료 알림 출력\n","    else:  # 가중치 파일이 존재하지 않는 경우\n","        print(\"No weights found in RVC backup.\")  # 가중치 파일 없음 알림 출력\n","    print(\"RVC backup import completed.\")  # RVC 백업 가져오기 완료 알림 출력\n","\n","# 파일의 MD5 해시 값을 계산하는 함수 정의\n","def get_md5_hash(file_path):\n","    hash_md5 = hashlib.md5()  # MD5 해시 객체 생성\n","    with open(file_path, \"rb\") as f:  # 파일을 바이너리 읽기 모드로 엶\n","        for chunk in iter(lambda: f.read(4096), b\"\"):  # 파일을 4096 바이트씩 읽어옴\n","            hash_md5.update(chunk)  # 읽어온 청크를 MD5 해시 객체에 업데이트\n","    return hash_md5.hexdigest()  # 최종 해시 값을 16진수 문자열로 반환\n","\n","# 가중치 폴더를 RVC 백업 폴더로 복사하는 함수 정의\n","def copy_weights():\n","    destination_folder = os.path.join(RVC_BK_PATH, \"weights\")  # 목적지 폴더 경로 생성\n","    try:  # 예외 처리를 위한 try 블록 시작\n","        if not os.path.exists(destination_folder):  # 목적지 폴더가 존재하지 않는 경우\n","            os.makedirs(destination_folder)  # 목적지 폴더 생성\n","\n","        num_copied = 0  # 복사된 파일 개수 초기화\n","        for filename in os.listdir(WEIGHTS_FOLDER):  # WEIGHTS_FOLDER 내 파일 목록 반복\n","            if filename.endswith(\".pth\"):  # 파일명이 .pth로 끝나는 경우\n","                source_file = os.path.join(WEIGHTS_FOLDER, filename)  # 소스 파일 경로 생성\n","                destination_file = os.path.join(destination_folder, filename)  # 목적지 파일 경로 생성\n","                if not os.path.exists(destination_file):  # 목적지 파일이 존재하지 않는 경우\n","                    shutil.copy2(source_file, destination_file)  # 소스 파일을 목적지 파일로 복사 (메타데이터 포함)\n","                    num_copied += 1  # 복사된 파일 개수 증가\n","                    print(f\"Copied {filename} to RVC Backup!\")  # 복사 완료 메시지 출력\n","\n","        if num_copied == 0:  # 복사된 파일이 없는 경우\n","            print(\"No new finished models found for copying.\")  # 복사할 새로운 모델이 없다는 메시지 출력\n","        else:  # 복사된 파일이 있는 경우\n","            print(f\"Finished copying {num_copied} files to RVC Backup!\")  # 복사 완료된 파일 개수 출력\n","\n","    except Exception as e:  # 예외가 발생한 경우\n","        print(f\"An error occurred while copying weights: {str(e)}\")  # 예외 메시지 출력\n","\n","def backup_files():  # 파일을 백업하는 함수 정의\n","    print(\"\\nStarting backup loop...\")  # 백업 루프 시작 알림 출력\n","    last_backup_timestamps_path = os.path.join(\n","        LOGS_FOLDER, \"last_backup_timestamps.txt\"\n","    )  # 마지막 백업 타임스탬프 파일 경로 생성\n","    fully_updated = False  # 모든 파일이 업데이트 되었는지 여부를 나타내는 플래그 초기화\n","\n","    while True:  # 무한 루프 시작\n","        try:  # 예외 처리를 위한 try 블록 시작\n","            updated = False  # 업데이트 여부를 나타내는 플래그 초기화\n","            last_backup_timestamps = {}  # 마지막 백업 타임스탬프를 저장할 딕셔너리 초기화\n","\n","            try:  # 파일 읽기를 위한 예외 처리 블록\n","                with open(last_backup_timestamps_path, \"r\") as f:  # 타임스탬프 파일 읽기\n","                    last_backup_timestamps = dict(line.strip().split(\":\") for line in f)  # 파일 내용을 딕셔너리로 변환\n","            except FileNotFoundError:  # 파일이 존재하지 않는 경우 예외 처리\n","                pass  # 예외 발생 시 아무것도 하지 않음\n","\n","            for root, dirs, files in os.walk(LOGS_FOLDER):  # LOGS_FOLDER 내 파일 및 디렉토리 탐색\n","                if \"zips\" in dirs:  # \"zips\" 디렉토리 제외\n","                    dirs.remove(\"zips\")\n","                if \"mute\" in dirs:  # \"mute\" 디렉토리 제외\n","                    dirs.remove(\"mute\")\n","                for filename in files:  # 파일 목록 반복\n","                    if filename != \"last_backup_timestamps.txt\":  # 타임스탬프 파일 제외\n","                        filepath = os.path.join(root, filename)  # 파일 경로 생성\n","                        if os.path.isfile(filepath):  # 파일이 존재하는 경우\n","                            backup_filepath = os.path.join(\n","                                RVC_BK_PATH,\n","                                os.path.relpath(filepath, LOGS_FOLDER),\n","                            )  # 백업 파일 경로 생성\n","                            backup_folderpath = os.path.dirname(backup_filepath)  # 백업 폴더 경로 생성\n","                            if not os.path.exists(backup_folderpath):  # 백업 폴더가 존재하지 않는 경우\n","                                os.makedirs(backup_folderpath)  # 백업 폴더 생성\n","                                print(\n","                                    f\"Created backup folder: {backup_folderpath}\",\n","                                    flush=True,\n","                                )  # 폴더 생성 알림 출력\n","                            last_backup_timestamp = last_backup_timestamps.get(filepath)  # 마지막 백업 타임스탬프 가져오기\n","                            current_timestamp = os.path.getmtime(filepath)  # 현재 파일의 수정 타임스탬프 가져오기\n","                            if (\n","                                last_backup_timestamp is None\n","                                or float(last_backup_timestamp) < current_timestamp\n","                            ):  # 파일이 새로 생성되었거나 업데이트된 경우\n","                                shutil.copy2(filepath, backup_filepath)  # 파일을 백업 경로로 복사 (메타데이터 포함)\n","                                last_backup_timestamps[filepath] = str(\n","                                    current_timestamp\n","                                )  # 최신 타임스탬프 업데이트\n","                                if last_backup_timestamp is None:  # 새로운 파일인 경우\n","                                    print(f\"Backed up file: {filename}\")  # 백업 완료 메시지 출력\n","                                else:  # 업데이트된 파일인 경우\n","                                    print(f\"Updating backed up file: {filename}\")  # 업데이트 완료 메시지 출력\n","                                updated = True  # 업데이트 플래그 설정\n","                                fully_updated = False  # 모든 파일 업데이트 플래그 해제\n","\n","            for filepath in list(last_backup_timestamps.keys()):  # 타임스탬프 딕셔너리 내 파일 경로 반복\n","                if not os.path.exists(filepath):  # 파일이 삭제된 경우\n","                    backup_filepath = os.path.join(\n","                        RVC_BK_PATH, os.path.relpath(filepath, LOGS_FOLDER)\n","                    )  # 백업 파일 경로 생성\n","                    if os.path.exists(backup_filepath):  # 백업 파일이 존재하는 경우\n","                        os.remove(backup_filepath)  # 백업 파일 삭제\n","                        print(f\"Deleted file: {filepath}\")  # 파일 삭제 메시지 출력\n","                    del last_backup_timestamps[filepath]  # 타임스탬프 딕셔너리에서 파일 경로 삭제\n","                    updated = True  # 업데이트 플래그 설정\n","                    fully_updated = False  # 모든 파일 업데이트 플래그 해제\n","\n","            if not updated and not fully_updated:  # 파일이 업데이트되지 않았고 모든 파일이 업데이트된 경우\n","                print(\"Files are up to date.\")  # 파일이 최신 상태라는 메시지 출력\n","                fully_updated = True  # 모든 파일 업데이트 플래그 설정\n","                sleep_time = 15  # 대기 시간 설정\n","            else:  # 파일이 업데이트된 경우\n","                sleep_time = 0.1  # 짧은 대기 시간 설정\n","\n","            with open(last_backup_timestamps_path, \"w\") as f:  # 타임스탬프 파일 쓰기 모드로 열기\n","                for filepath, timestamp in last_backup_timestamps.items():  # 타임스탬프 딕셔너리 내 항목 반복\n","                    f.write(f\"{filepath}:{timestamp}\\n\")  # 파일에 타임스탬프 기록\n","\n","            time.sleep(sleep_time)  # 설정된 시간 동안 대기\n","\n","        except Exception as e:  # 예외가 발생한 경우\n","            print(f\"An error occurred: {str(e)}\")  # 예외 메시지 출력\n","\n","# def start_train():\n","#     !python core.py train --model_name \"{model_name}\" --rvc_version \"{rvc_version}\" --save_every_epoch \"{save_every_epoch}\" --save_only_latest \"{save_only_latest}\" --save_every_weights \"{save_every_weights}\" --total_epoch \"{total_epoch}\" --sampling_rate \"{sr}\" --batch_size \"{batch_size}\" --gpu \"{gpu}\" --pitch_guidance \"{pitch_guidance}\" --pretrained \"{pretrained}\" --custom_pretrained \"{custom_pretrained}\" --g_pretrained_path \"{g_pretrained_path}\" --d_pretrained_path \"{d_pretrained_path}\" --overtraining_detector \"{overtraining_detector}\" --overtraining_threshold \"{overtraining_threshold}\" --sync_graph \"{sync_graph}\" --cache_data_in_gpu \"{cache_data_in_gpu}\"\n","\n","# server_thread = threading.Thread(target=start_train)\n","# server_thread.start()\n","!python core.py train --model_name \"{model_name}\" --rvc_version \"{rvc_version}\" --save_every_epoch \"{save_every_epoch}\" --save_only_latest \"{save_only_latest}\" --save_every_weights \"{save_every_weights}\" --total_epoch \"{total_epoch}\" --sampling_rate \"{sr}\" --batch_size \"{batch_size}\" --gpu \"{gpu}\" --pitch_guidance \"{pitch_guidance}\" --pretrained \"{pretrained}\" --custom_pretrained \"{custom_pretrained}\" --g_pretrained_path \"{g_pretrained_path}\" --d_pretrained_path \"{d_pretrained_path}\" --overtraining_detector \"{overtraining_detector}\" --overtraining_threshold \"{overtraining_threshold}\" --sync_graph \"{sync_graph}\" --cache_data_in_gpu \"{cache_data_in_gpu}\""]},{"cell_type":"markdown","metadata":{"id":"tLCuADFsq0ex"},"source":["## Generate index file"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":81769,"status":"ok","timestamp":1721640714189,"user":{"displayName":"DongKyu Moon","userId":"13679376230758781592"},"user_tz":-540},"id":"wRWCG413q0ex","outputId":"fd007d20-a73e-46c4-8f07-a1ce15b0c832"},"outputs":[],"source":["!python core.py index --model_name \"{model_name}\" --rvc_version \"{rvc_version}\""]},{"cell_type":"markdown","metadata":{"id":"u3MbGJWrq0ex"},"source":["## Save RVC Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":157},"executionInfo":{"elapsed":8180,"status":"ok","timestamp":1721640725869,"user":{"displayName":"DongKyu Moon","userId":"13679376230758781592"},"user_tz":-540},"id":"KqxmBku_q0ex","outputId":"77566dce-cd69-4b87-8376-24303f08914b"},"outputs":[],"source":["if os.path.exists(model_path):  # model_path 경로가 존재하는지 확인\n","    shutil.rmtree(model_path)  # 해당 경로 및 그 하위 파일/폴더 삭제\n","print(\"Removed zips.\")  # 삭제 완료 메시지 출력\n","\n","os.makedirs(model_path)  # model_path 경로 생성\n","print(\"Created zips.\")  # 생성 완료 메시지 출력\n","\n","model_pth = os.path.join(model_path, f\"{model_name}.pth\")  # 모델 파일 경로 생성\n","if model_pth not in os.listdir(\"./weights\"):  # 모델 파일이 백업 폴더에 없는지 확인\n","    print(\"There is no weight file with that name\")  # 해당 이름의 가중치 파일이 없음을 알림\n","\n","if not save_big_file:  # save_big_file 플래그가 False인 경우\n","    !cp ./logs/{model_name}/added_*.index ./models/{model_name}/  # 로그 파일을 models 폴더로 복사\n","    !cp ./logs/{model_name}/total_*.npy ./models/{model_name}/  # 로그 파일을 models 폴더로 복사\n","    !cp ./logs/{model_name}_200e_*.pth ./models/{model_name}/{model_name}.pth\n","    # !cp ./weights/{model_name}.pth ./models/{model_name}/{model_name}.pth  # 가중치 파일을 models 폴더로 복사\n","    # %cd ./models/{model_name}/  # zips 폴더로 이동\n","    !zip -r ./models/{model_name}/{model_name}.zip ./models/{model_name}  # models 폴더의 파일들을 압축\n","\n","if save_big_file:  # save_big_file 플래그가 True인 경우\n","    latest_steps = -1  # 최신 스텝 초기화\n","    logs_folder = \"./logs/\" + model_name  # 로그 폴더 경로 생성\n","    for filename in os.listdir(logs_folder):  # 로그 폴더의 파일 목록 반복\n","        if filename.startswith(\"G_\") and filename.endswith(\".pth\"):  # G_로 시작하고 .pth로 끝나는 파일 찾기\n","            steps = int(filename.split(\"_\")[1].split(\".\")[0])  # 스텝 수 추출\n","            if steps > latest_steps:  # 최신 스텝 수 업데이트\n","                latest_steps = steps\n","\n","    MODELZIP = model_name + \".zip\"  # 모델 압축 파일 이름 생성\n","    !mkdir -p ./models\n","    ZIPFILEPATH = os.path.join(\"./models\", MODELZIP)  # 압축 파일 경로 생성\n","    for filename in os.listdir(logs_folder):  # 로그 폴더의 파일 목록 반복\n","        if \"G_\" in filename or \"D_\" in filename:  # G_ 또는 D_가 파일명에 포함된 경우\n","            if str(latest_steps) in filename:  # 최신 스텝 수가 파일명에 포함된 경우\n","                !zip -r {ZIPFILEPATH} {os.path.join(logs_folder, filename)}  # 파일을 압축\n","        else:  # 그 외 파일\n","            !zip -r {ZIPFILEPATH} {os.path.join(logs_folder, filename)}  # 파일을 압축\n","    for filename in os.listdir(\"./weights\"):  # weights 폴더의 파일 목록 반복\n","        if model_name in filename:  # 모델 이름이 파일명에 포함된 경우\n","            !zip -r {ZIPFILEPATH} {os.path.join('./weights/', filename)}  # 파일을 압축\n","\n","shutil.move(\n","    f\"./models/{model_name}/{model_name}.zip\",\n","    f\"./RVC_Backup/{model_name}.zip\",\n",")  # 압축 파일을 백업 폴더로 이동\n","\n","# shutil.rmtree(\"/home/chwang/KT/BP/voice_generator/applio_content/zips\")  # zips 폴더 삭제"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p__MMkImq0ex"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["qFVtVLU0q0ev"],"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":0}
