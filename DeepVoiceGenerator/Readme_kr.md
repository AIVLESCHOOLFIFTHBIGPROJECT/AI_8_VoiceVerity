# Deep Voice Generator

## 우리 프로젝트

### 프로젝트 개요

- 이 프로젝트의 목적은 한국어 딥 보이스 분류 모델 개발을 용이하게 하기 위해 한국어로 된 딥 페이크 음성의 포괄적인 데이터셋을 생성하는 것이다. 기존에 한국어 딥 페이크 음성을 포함하는 데이터셋이 부족하기 때문에, 우리는 직접 데이터셋을 생성하기로 결정했다. 이를 위해 Deep Voice Generator를 사용하여 다양한 성별, 연령대, 지역 방언 및 발화 특성을 포함한 다양한 인구 통계를 대표하는 합성 음성을 생성한다.

### 프로젝트 목표

1. 딥 페이크 음성 데이터 생성: Deep Voice Generator를 사용하여 견고한 데이터셋을 구축하기 위한 합성 음성을 생성한다.

2. 데이터셋 구축: 실제 음성과 합성 음성을 포함하는 포괄적인 데이터셋을 컴파일하여 다양한 인구 통계를 포괄한다.

3. 딥 보이스 분류 모델: 생성된 데이터셋을 사용하여 실제 음성과 딥 페이크 음성을 정확하게 구별할 수 있는 모델을 개발한다.

### 프로젝트 주요 단계

1. 데이터 수집:

    - 출처: AI Hub의 다음 카테고리 데이터를 활용한다:

        - 뉴스 대본 및 앵커 음성

        - 자유대화 음성 (혼합 성별, 어린이)

        - 자유대화 음성 (노인, 혼합 성별)

        - 자유대화 음성 (일반인, 혼합 성별)

        - 인구 통계 다양성: 성별, 연령대, 지역 방언 및 발화 특성을 포함하는 실제 음성 데이터를 수집한다.

2. 딥 보이스 생성:

    - 모델 선택: 음성 합성을 위해 Applio의 오픈 소스 RVC 모델을 사용한다.

    - 전이 학습: RVC 모델에 전이 학습을 적용하여 다음 인구 통계에 대한 합성 음성을 생성한다:

        - 어린이 (11명)

        - 성인 (33명)

        - 노인 (10명)

    - 데이터 생성: 각 인구 통계 그룹별로 약 210개의 어린이 샘플, 740개의 성인 샘플, 290개의 노인 샘플을 생성한다.

### 세부 과정

#### 데이터 수집

1. 실제 음성 데이터:

    - AI Hub 데이터: AI Hub의 카테고리에서 실제 음성 데이터를 추출하여 다양한 인구 통계를 균형 있게 대표한다.

    - 인구 통계 정보: 각 샘플에 성별, 연령대, 지역 방언 및 기타 관련 발화 특성을 지정하는 메타데이터를 포함한다.

2. 데이터 전처리:

    - 정규화: 오디오 데이터의 볼륨과 품질의 일관성을 보장하기 위해 정규화한다.

    - 세분화: 오디오 파일을 훈련 및 합성에 적합한 관리 가능한 길이로 분할한다.

#### 딥 보이스 생성

1. 모델 훈련:

    - RVC 모델: 음성 합성을 위해 Applio의 RVC 모델을 설정하고 구성한다.

    - 전이 학습: 수집된 실제 음성 데이터를 사용하여 RVC 모델을 미세 조정하여 딥 페이크 음성을 생성한다.

    - 인구 통계 그룹: 각 인구 통계 그룹(어린이, 성인, 노인)에 대한 음성을 생성하기 위해 별도의 모델을 훈련하거나 적절한 조건을 사용한다.

2. 데이터 생성:

    - 합성 음성 샘플: 각 인구 통계 그룹에 대해 발화 패턴 및 특성의 다양성을 보장하며 딥 페이크 음성 샘플을 생성한다.

    - 품질 관리: 생성된 음성이 현실적이고 고품질인지 보장하기 위해 품질 관리 조치를 구현한다.

#### 데이터셋 구축

1. 실제 데이터와 합성 데이터 결합:

    - 균형 잡힌 데이터셋: 실제 음성과 합성 음성을 결합하여 분류 모델 훈련을 위한 균형 잡힌 데이터셋을 만든다.

    - 메타데이터: 각 샘플에 대한 자세한 메타데이터를 유지하여 실제인지 합성인지 및 인구 통계 정보를 포함한다.

2. 데이터셋 증강:

    - 추가 증강: 데이터 증강 기법을 적용하여 데이터셋을 더욱 다양화하고 모델의 견고성을 향상시킨다.

#### 응용: 딥 보이스 분류

1. 모델 개발:

    - 특성 추출: 오디오 샘플을 분류 모델에 입력하기 위해 멜-스펙트로그램으로 변환한다.

    - 모델 훈련: 준비된 데이터셋을 사용하여 Vision Transformer (ViT) 모델을 훈련시켜 실제 음성과 딥 페이크 음성을 구별한다.

    - 평가: 표준 메트릭을 사용하여 모델을 평가하여 높은 정확도와 신뢰성을 보장한다.

2. 배포:

    - ONNX 변환: 훈련된 분류 모델을 ONNX 형식으로 변환하여 배포한다.

    - 실시간 응용 프로그램: 보안 및 미디어 검증과 같은 실시간 딥 페이크 음성 감지가 필요한 응용 프로그램에 모델을 배포한다.
